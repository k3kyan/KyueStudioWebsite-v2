# GOOD FOR STORING API KEYS, AWS S3 keys, credentials to external services like Amazon S3 or twitter, etc, API Keys, passwords, database configs, secret keys, authentication keys, credentials

# AWS Secrets Manager : sensitive keys
API_BASE_URL=http://localhost:5173
MY_SECRET_KEY = "sdlkfjslf"
ADMIN_USERNAME = "tempUsernameEV"
ADMIN_PASSWORD = "tempPasswordEV"


# # AWS Lambda Environmental Variables : ok to share ig ..? 
# # EMAIL_DOMAIN = "@kyuestudio.com"
# # EMAIL = ks${EMAIL_DOMAIN}

# # kinda cool i just realized the .gitignore file already has this marked as not for upload wowow!!!


# # To access lambda environment variables, just keep using os.getenv() or whatever from python-dotenv
# # TO access the secrets manager variables in app, MUST ACCESS USING BOTO3 !!! 
#     # secrets_client = boto3.client('secretsmanager')
#     # secret_value = secrets_client.get_secret_value(SecretId = 'kyue-fastapi-secrets') // the secret's name is here ...? IDK I'LL LOOK INTO THIS AGAIN LATER. 
#     # secrets = json.loads(secret_value['SecretString'])
#     # JWT_SECRET = secrets["JWT_SECRET"]


# # DO NOT MANUALLY EDIT LAMBDA ENV VARIABLES bc it'll be overwritten next time cloudformation deploys. 


# # SO FOR SECRETS MANAGER, to create those secret environment variables:
#     # 1. Create secrets manually (one time)
#     # 2. reference by name in cloudformation
#     # make sure the secret created in AWS Secrets Manager, the name is the same as the one referenced in the Cloudformation buildspec.yml

#     # or something like that...? i think? idk.... research later.... 
#     # just reference the secret (that i created manually) inside the yml ... ? 
#     # will need an IAM policy to allow Lambda to read kyuestudiosecrets. not sure if this is done in cloudformation or manually....?







# # To get the variables in another file
# from dotenv import load_dotenv
# import os

# # load only one file depending on context
# env_file = ".env.production" if os.getenv("ENV") == "production" else ".env.local"
# load_dotenv(env_file)

# print(os.getenv("S3_BUCKET"))

# # NOTE: TODO: RESEARCH ???? : if you deploy to AWS Lambda, I DONT NEED .ENV.PRODUCTION !!!!! You can use REAL LAMBDA ENVIRONMENT VARIALBES (though aws console or cloudformation)
# # but ig its good to have a .env.local backend because it'll remind me what env variables i need to upload to AWS, helps keep it matching



# # OK SO since i'm using AWS, i dont need a .env.production file !!!!  Instead, it'll be
# # Lambda Environment Variables: will hold non-secret configs like ENV, S3_BUCKET, DB_MODE
# # AWS Secrets Manager (or SSM parameter store): FOR SENSITIVE VALUES (DB credentials, secret keys, JWT secrets)

# # use os.getenv("ENV")
# # because that will pull directly from Lambda's environmental variables

# # TODO: WHEN MAKING CLOUDFORMATION, define lambda environment variables,
# ENV = local
# S3_BUCKET = aws-s3-bucket-name
# DB_MODE = AWS












# # Examples
# # .env.local
# ENV = local
# DB_MODE = local
# S3_BUCKET = /data/content

# # .env.production
# ENV = production
# DB_MODE = AWS
# S3_BUCKET = aws-s3-bucket-name


# # Place .env.local in the root of your backend directory, typically alongside your main.py or settings.py file.
















# # Previously from main.py, worked nicely!
# from dotenv import load_dotenv, dotenv_values, find_dotenv
# import os
# load_dotenv(".env.local") # loads the .env file

# # # Load environment variables from .env file
# # # env_var_path = find_dotenv(".env.local") // default is just find_dotenv() if ur file is named just .env
# # load_dotenv(".env.local")
# # ADMIN_USERNAME = os.getenv("ADMIN_USERNAME")
# # print ("Admin username:", ADMIN_USERNAME)
# # # dict way (WORKS)
# # env_var = dotenv_values(".env.local")
# # ADMIN_PASSWORD = env_var["ADMIN_PASSWORD"]
# # print ("Dict Method: Admin username:", ADMIN_PASSWORD)

